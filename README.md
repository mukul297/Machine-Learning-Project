#Quantisation of Neural Network

Todayâ€™s world, neural network is doing amazing things. Starting from real time object detection, image recognition to NLP. It requires high power intensive devices like GPU, TPU to run because these tasks requires thousands and millions of addition and multiplication of floating point numbers. It also requires high storage system because we have to store millions of parameters and weights to train the model.

1. Train the Lenet network with binarization techniques.
2. I have to conduct experiments to prove that BNN can achieve the state-of-the-art result on MNIST dataset(more than 97%).
3. During forward field, BNN drastically reduces the memory consumption and replaces all the arithmetic operation with bitwise operation. 
